{"name":"Practical machine learning","tagline":"Coursera course Practical Machine Learning by JHU","body":"---\r\ntitle: \"Prediction assessment write up\"\r\noutput: html_document\r\n---\r\n\r\nThis is the writeup for the coursera course machine learning. The datasets are obtained at the following websites on May 18, 2015. \r\ntraining set: \r\nhttps://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv\r\ntesting set:\r\nhttps://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv\r\n\r\nFirst of all, I loaded the training dataset, and splitted them into train and test subsets in order to perform cross-validation. \r\n\r\n```r\r\nlibrary(caret)\r\nset.seed(1)\r\npmltrain<- read.csv(\"pml-training.csv\", na.strings=c(\"NA\", \"#DIV/0!\"))\r\nintrain<- createDataPartition(y=pmltrain$classe, p=0.7, list=F)\r\ntrain<- pmltrain[intrain,]\r\ntest<- pmltrain[-intrain,]\r\ntrainx<-train[,-160]\r\ntrainy<- train[,160]\r\ntestx<- test[,-160]\r\ntesty<- test[,160]\r\n```\r\n\r\nFor pre-processing, I did three things to simplify the model fitting part. First of all, since many variables have extensive NAs, I got rid of these variables. Secondely, I eliminated the variables with near zero variance. In addition, I discarded the obvious irrelavent variables such as username and timestamp. Also, by analysis of correlation, we can see some of the variables are highly correlated, I removed them as well.\r\n\r\n\r\n```r\r\ntrainx1<- trainx[, colSums(is.na(trainx))<10000] #discard the varialbes with too many NAs\r\ntrainx2<- trainx1[, -nearZeroVar(trainx1)] #delete variables with little variance\r\ntrainx3<- trainx2[,-c(1,2,5)] #remove username, timestamp and the sample number\r\ncorrelations<- cor(trainx3)\r\nlibrary(corrplot)\r\ncorrplot(correlations, order=\"hclust\", tl.cex=.5, title=\"Correlation of variables\")\r\n```\r\n\r\n![plot of chunk unnamed-chunk-2](figure/unnamed-chunk-2-1.png) \r\n\r\n```r\r\nhighCor<- findCorrelation(correlations, cutoff=0.75)\r\ntrainx4<- trainx3[,-highCor] #remove highly correlated variables\r\n```\r\n\r\nAfter the pre-process, I can fit the model using random forest classification. \r\n\r\n\r\n```r\r\nmodel<- train(trainy~., data=trainx4, method=\"rf\")\r\n```\r\n\r\nHere I get the model I want, 'r model'. I would like to apply it to the validation subset that I generated at the beginning of this assignment, to see how does the model work. \r\n\r\n\r\n```r\r\nprediction<- predict(model, testx)\r\ntable(prediction=prediction, true=testy)\r\n```\r\n\r\n```\r\n##           true\r\n## prediction    A    B    C    D    E\r\n##          A 1674    1    0    0    0\r\n##          B    0 1138    2    0    0\r\n##          C    0    0 1024    0    0\r\n##          D    0    0    0  964    2\r\n##          E    0    0    0    0 1080\r\n```\r\n\r\nFrom the confusion matrix we can see that the model did a good job on the validation data subset. \r\n\r\nFor the real test data, I picked the variables that I fitted for the model and then did prediction on them: \r\n\r\n```r\r\npmltest<- read.csv(\"pml-testing.csv\")\r\npmltestx<- pmltest[,-160]\r\nprediction2<- predict(model, pmltestx)\r\nprediction2\r\n```\r\n\r\n```\r\n##  [1] B A B A A E D B A A B C B A E E A B B B\r\n## Levels: A B C D E\r\n```\r\n\r\nHere I got the final test result that I want. I would then submit them in the format required. \r\n\r\n```r\r\npml_write_files<- function(x) {\r\n  n=length(x)\r\n  for(i in 1:n) {\r\n    filename=paste0(\"problem_id_\",i,\".txt\")\r\n    write.table(x[i], file=filename,quote=F, row.names=F, col.names=F)\r\n  }\r\n}\r\npml_write_files(prediction2)\r\n```\r\n\r\nFinally, I generated the markdown file using knitr. \r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}